# Personal Assistant Discord Bot - Complete Build Guide

**Build a NEW Discord bot from scratch** - personal AI assistant with:
- Accurate memory (no hallucinations)
- Todo list & reminders  
- Dual database (Vector + SQL)
- Immediate + batch storage
- Context-aware responses

This guide provides complete code for building the bot from zero. Copy/paste each file as you build.

---

## Core Design Principles

**1. Memory Accuracy**
- Extract from raw conversations, not summaries
- Temperature 0.1 for facts (not 0.7)
- Strict anti-hallucination prompts
- Track source messages

**2. Dual Database**
- ChromaDB: Time-irrelevant (preferences, traits)
- Prisma + SQLite: Time-relevant (events, dates, todos)

**3. Smart Storage**  
- Immediate: AI detects important info ‚Üí store right away
- Batch (11 PM): Process remaining conversations
- Semantic deduplication prevents duplicates

**Why Prisma?**
- Type-safe database queries (autocomplete!)
- Automatic migrations
- Clean, intuitive API
- Built-in Prisma Studio for database visualization
- Easy schema changes without manual SQL

---

## System Architecture

### Directory Structure
```
assistant-bot/
‚îú‚îÄ‚îÄ prisma/
‚îÇ   ‚îî‚îÄ‚îÄ schema.prisma      # Prisma database schema
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ commands/          # Bot commands (!todo, !remind, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ events/            # Discord event handlers (ready, message)
‚îÇ   ‚îú‚îÄ‚îÄ handlers/          # Command & event loaders
‚îÇ   ‚îú‚îÄ‚îÄ modules/           # Core functionality
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ aiChat.js      # AI conversation handler
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vectorDB.js    # ChromaDB operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sqlDB.js       # Prisma database operations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ memoryProcessor.js  # Memory extraction & categorization
‚îÇ   ‚îú‚îÄ‚îÄ utils/             # Utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.js      # Logging
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scheduler.js   # Cron jobs
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îî‚îÄ‚îÄ config.js      # Configuration
‚îú‚îÄ‚îÄ data/                  # Databases (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ assistant.db       # SQLite database
‚îÇ   ‚îî‚îÄ‚îÄ chroma/            # ChromaDB storage
‚îú‚îÄ‚îÄ .env                   # Environment variables
‚îú‚îÄ‚îÄ index.js               # Entry point
‚îî‚îÄ‚îÄ package.json
```

### Database Architecture
```
Vector DB (ChromaDB):
‚îî‚îÄ‚îÄ Time-irrelevant knowledge
    ‚îú‚îÄ‚îÄ User preferences ("likes pizza", "prefers dark mode")
    ‚îú‚îÄ‚îÄ Relationships ("best friend is John")
    ‚îú‚îÄ‚îÄ Skills/knowledge ("knows Python", "learning Japanese")
    ‚îî‚îÄ‚îÄ Personality traits ("jokes a lot", "helpful with code")

Relational DB (Prisma + SQLite):
‚îú‚îÄ‚îÄ Event              # What happened when
‚îÇ   ‚îú‚îÄ‚îÄ id, date, description, participants, context, createdAt
‚îÇ
‚îú‚îÄ‚îÄ Todo               # Task list
‚îÇ   ‚îú‚îÄ‚îÄ id, task, dueDate, completed, priority, createdAt
‚îÇ
‚îú‚îÄ‚îÄ Reminder           # Scheduled notifications
‚îÇ   ‚îú‚îÄ‚îÄ id, triggerTime, message, recurring, completed, createdAt
‚îÇ
‚îî‚îÄ‚îÄ ProcessedMessage   # Prevent duplicate processing
    ‚îî‚îÄ‚îÄ messageId, processedAt, processingType, storedIn
```

### Data Flow

#### 1. User Message ‚Üí AI Response
```
User sends message to bot
  ‚Üì
Add to conversation_cache (with message_id, timestamp)
  ‚Üì
AI detects importance (with 10-message context window)
  ‚Üì
IF IMPORTANT:
  ‚îú‚îÄ Extract facts with context awareness
  ‚îú‚îÄ Check semantic duplicates in Vector DB
  ‚îú‚îÄ Categorize: fact|event|todo|reminder
  ‚îú‚îÄ Store in appropriate database
  ‚îî‚îÄ Mark message_id as processed
  ‚Üì
Search Vector DB (time-irrelevant context)
  ‚Üì
Query Prisma DB (recent events, pending todos)
  ‚Üì
Combine context + conversation_cache
  ‚Üì
GPT-4o generates response
  ‚Üì
Send to Discord
```

#### 2. Daily Batch Processing (11 PM)
```
Cron triggers at 11 PM
  ‚Üì
Collect unprocessed messages from conversation_cache
  ‚Üì
IF messages exist:
  ‚îú‚îÄ LLM categorizes into time-relevant vs time-irrelevant
  ‚îú‚îÄ Time-irrelevant ‚Üí Chunk ‚Üí Store in Vector DB
  ‚îú‚îÄ Time-relevant ‚Üí Structure ‚Üí Store in SQL DB
  ‚îî‚îÄ Mark all message_ids as processed
  ‚Üì
Clear conversation_cache
  ‚Üì
Log summary
```

---

## IMPLEMENTATION GUIDE

## Phase 0: Project Setup

### Step 1: Initialize Project
```bash
mkdir assistant-bot
cd assistant-bot
npm init -y
```

### Step 2: Install Dependencies
```bash
npm install discord.js@12.5.3 openai@4.0.0 chromadb@1.5.0 @prisma/client dotenv node-cron uuid chalk@4.1.2
npm install -D nodemon prisma
```

### Step 2b: Initialize Prisma
```bash
npx prisma init --datasource-provider sqlite
```

### Step 3: Create Directory Structure
```bash
mkdir -p src/{commands,events,handlers,modules,utils,config} data
```

### Step 4: Create .env File
```env
DISCORD_TOKEN=your_discord_bot_token
DISCORD_CLIENT_ID=your_client_id
PREFIX=!
OPENAI_API_KEY=your_openai_api_key

# Vector DB (ChromaDB)
CHROMA_PATH=http://localhost:8000
CHROMA_COLLECTION=assistant_memories

# Prisma Database
DATABASE_URL="file:./data/assistant.db"

# Memory settings
IMPORTANCE_THRESHOLD=0.7
DEDUP_SIMILARITY_THRESHOLD=0.15
CONTEXT_WINDOW_SIZE=10
```

### Step 5: Create Prisma Schema

**File:** `prisma/schema.prisma`

```prisma
generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "sqlite"
  url      = env("DATABASE_URL")
}

model Event {
  id           Int      @id @default(autoincrement())
  date         String
  description  String
  participants String?
  context      String?
  createdAt    DateTime @default(now())

  @@index([date])
}

model Todo {
  id        Int      @id @default(autoincrement())
  task      String
  dueDate   String?
  completed Boolean  @default(false)
  priority  String   @default("normal")
  createdAt DateTime @default(now())

  @@index([completed])
}

model Reminder {
  id          Int      @id @default(autoincrement())
  triggerTime String
  message     String
  recurring   String?
  completed   Boolean  @default(false)
  createdAt   DateTime @default(now())

  @@index([triggerTime, completed])
}

model ProcessedMessage {
  messageId      String   @id
  processedAt    DateTime @default(now())
  processingType String
  storedIn       String?
}
```

### Step 6: Run Prisma Migration
```bash
npx prisma migrate dev --name init
```

### Step 7: Create .gitignore
```
node_modules/
.env
data/
*.log
prisma/migrations/
```

### Step 8: Update package.json scripts
```json
{
  "scripts": {
    "start": "node index.js",
    "dev": "nodemon index.js",
    "db:migrate": "npx prisma migrate dev",
    "db:studio": "npx prisma studio"
  }
}
```

---

## Phase 1: Core Bot Setup

### Create: `src/config/config.js`
```javascript
require('dotenv').config();

module.exports = {
  discord: {
    token: process.env.DISCORD_TOKEN,
    clientId: process.env.DISCORD_CLIENT_ID,
    prefix: process.env.PREFIX || '!',
  },
  
  openai: {
    apiKey: process.env.OPENAI_API_KEY,
  },
  
  vectorDB: {
    path: process.env.CHROMA_PATH || 'http://localhost:8000',
    collectionName: process.env.CHROMA_COLLECTION || 'assistant_memories',
  },
  
  memory: {
    importanceThreshold: parseFloat(process.env.IMPORTANCE_THRESHOLD) || 0.7,
    dedupThreshold: parseFloat(process.env.DEDUP_SIMILARITY_THRESHOLD) || 0.15,
    contextWindowSize: parseInt(process.env.CONTEXT_WINDOW_SIZE) || 10,
    batchSchedule: '0 23 * * *', // 11 PM daily
  }
};
```

### Create: `src/utils/logger.js`
```javascript
const chalk = require('chalk');

const logger = {
  info: (message, ...args) => {
    console.log(chalk.blue('[INFO]'), message, ...args);
  },
  
  success: (message, ...args) => {
    console.log(chalk.green('[SUCCESS]'), message, ...args);
  },
  
  warn: (message, ...args) => {
    console.log(chalk.yellow('[WARN]'), message, ...args);
  },
  
  error: (message, ...args) => {
    console.error(chalk.red('[ERROR]'), message, ...args);
  },
  
  debug: (message, ...args) => {
    if (process.env.DEBUG) {
      console.log(chalk.gray('[DEBUG]'), message, ...args);
    }
  }
};

module.exports = logger;
```

### Create: `src/handlers/eventHandler.js`
```javascript
const fs = require('fs');
const path = require('path');
const logger = require('../utils/logger');

module.exports = (client) => {
  const eventsPath = path.join(__dirname, '../events');
  const eventFiles = fs.readdirSync(eventsPath).filter(file => file.endsWith('.js'));

  for (const file of eventFiles) {
    const event = require(path.join(eventsPath, file));
    
    if (event.once) {
      client.once(event.name, (...args) => event.execute(...args, client));
    } else {
      client.on(event.name, (...args) => event.execute(...args, client));
    }
    
    logger.success(`Event loaded: ${event.name}`);
  }
};
```

### Create: `src/handlers/commandHandler.js`
```javascript
const fs = require('fs');
const path = require('path');
const { Collection } = require('discord.js');
const logger = require('../utils/logger');

module.exports = (client) => {
  client.commands = new Collection();
  
  const commandsPath = path.join(__dirname, '../commands');
  const commandFiles = fs.readdirSync(commandsPath).filter(file => file.endsWith('.js'));

  for (const file of commandFiles) {
    const command = require(path.join(commandsPath, file));
    client.commands.set(command.name, command);
    logger.success(`Command loaded: ${command.name}`);
  }
};
```

### Create: `src/events/ready.js`
```javascript
const logger = require('../utils/logger');

module.exports = {
  name: 'ready',
  once: true,
  execute: async (client) => {
    logger.success(`Logged in as ${client.user.tag}`);
    client.user.setActivity('your tasks', { type: 'WATCHING' });
  }
};
```

### Create: `src/events/message.js`
```javascript
const config = require('../config/config');
const logger = require('../utils/logger');
const { handleAIChat } = require('../modules/aiChat');

module.exports = {
  name: 'message',
  execute: async (message, client) => {
    // Ignore bots
    if (message.author.bot) return;

    const { prefix } = config.discord;

    // Handle prefix commands
    if (message.content.startsWith(prefix)) {
      const args = message.content.slice(prefix.length).trim().split(/ +/);
      const commandName = args.shift().toLowerCase();

      const command = client.commands.get(commandName) 
        || client.commands.find(cmd => cmd.aliases && cmd.aliases.includes(commandName));

      if (!command) return;

      try {
        await command.execute(message, args, client);
      } catch (error) {
        logger.error('Error executing command:', error);
        message.reply('There was an error executing that command.');
      }
      return;
    }

    // Handle mentions (AI chat)
    if (message.mentions.has(client.user)) {
      try {
        await handleAIChat(message, client);
      } catch (error) {
        logger.error('Error in AI chat:', error);
        message.reply('Sorry, I encountered an error processing your message.');
      }
    }
  }
};
```

### Create: `index.js`
```javascript
const Discord = require('discord.js');
const config = require('./src/config/config');
const logger = require('./src/utils/logger');

// Create Discord client
const client = new Discord.Client({
  partials: ['MESSAGE', 'CHANNEL', 'REACTION'],
  intents: [
    Discord.Intents.FLAGS.GUILDS,
    Discord.Intents.FLAGS.GUILD_MESSAGES,
    Discord.Intents.FLAGS.DIRECT_MESSAGES,
  ]
});

// Load handlers
require('./src/handlers/eventHandler')(client);
require('./src/handlers/commandHandler')(client);

// Initialize databases
const { initializeVectorDB } = require('./src/modules/vectorDB');
const { initializeSQL } = require('./src/modules/sqlDB');

(async () => {
  try {
    await initializeVectorDB();
    await initializeSQL();
    logger.success('Databases initialized');
  } catch (error) {
    logger.error('Failed to initialize databases:', error);
  }
})();

// Start scheduler
require('./src/utils/scheduler');

// Login to Discord
client.login(config.discord.token)
  .then(() => logger.success('Bot started successfully'))
  .catch(err => logger.error('Failed to login:', err));

// Handle errors
process.on('unhandledRejection', error => {
  logger.error('Unhandled promise rejection:', error);
});
```

---

## Phase 2: Prisma Database Module

### Create: `src/modules/sqlDB.js`

```javascript
const { PrismaClient } = require('@prisma/client');
const logger = require('../utils/logger');

const prisma = new PrismaClient();

/**
 * Initialize Prisma (connection test)
 */
async function initializeSQL() {
  try {
    // Test connection
    await prisma.$connect();
    logger.success('Prisma database connected successfully');
    return prisma;
  } catch (error) {
    logger.error('Failed to connect to database:', error);
    throw error;
  }
}

// === EVENTS ===
async function addEvent(date, description, participants = null, context = null) {
  try {
    const event = await prisma.event.create({
      data: {
        date,
        description,
        participants,
        context
      }
    });
    return event;
  } catch (error) {
    logger.error('Error adding event:', error);
    throw error;
  }
}

async function getRecentEvents(days = 7) {
  try {
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - days);
    
    const events = await prisma.event.findMany({
      where: {
        date: {
          gte: cutoffDate.toISOString()
        }
      },
      orderBy: {
        date: 'desc'
      }
    });
    return events;
  } catch (error) {
    logger.error('Error getting recent events:', error);
    return [];
  }
}

async function searchEvents(query) {
  try {
    const events = await prisma.event.findMany({
      where: {
        OR: [
          { description: { contains: query } },
          { context: { contains: query } }
        ]
      },
      orderBy: {
        date: 'desc'
      },
      take: 10
    });
    return events;
  } catch (error) {
    logger.error('Error searching events:', error);
    return [];
  }
}

// === TODOS ===
async function addTodo(task, dueDate = null, priority = 'normal') {
  try {
    const todo = await prisma.todo.create({
      data: {
        task,
        dueDate,
        priority
      }
    });
    return todo;
  } catch (error) {
    logger.error('Error adding todo:', error);
    throw error;
  }
}

async function getTodos(includeCompleted = false) {
  try {
    const where = includeCompleted ? {} : { completed: false };
    
    const todos = await prisma.todo.findMany({
      where,
      orderBy: [
        { completed: 'asc' },
        { createdAt: 'desc' }
      ]
    });
    return todos;
  } catch (error) {
    logger.error('Error getting todos:', error);
    return [];
  }
}

async function completeTodo(id) {
  try {
    const todo = await prisma.todo.update({
      where: { id },
      data: { completed: true }
    });
    return todo;
  } catch (error) {
    logger.error('Error completing todo:', error);
    throw error;
  }
}

async function deleteTodo(id) {
  try {
    const todo = await prisma.todo.delete({
      where: { id }
    });
    return todo;
  } catch (error) {
    logger.error('Error deleting todo:', error);
    throw error;
  }
}

// === REMINDERS ===
async function addReminder(triggerTime, message, recurring = null) {
  try {
    const reminder = await prisma.reminder.create({
      data: {
        triggerTime,
        message,
        recurring
      }
    });
    return reminder;
  } catch (error) {
    logger.error('Error adding reminder:', error);
    throw error;
  }
}

async function getUpcomingReminders(hours = 24) {
  try {
    const now = new Date();
    const future = new Date(now.getTime() + hours * 60 * 60 * 1000);
    
    const reminders = await prisma.reminder.findMany({
      where: {
        triggerTime: {
          gte: now.toISOString(),
          lte: future.toISOString()
        },
        completed: false
      },
      orderBy: {
        triggerTime: 'asc'
      }
    });
    return reminders;
  } catch (error) {
    logger.error('Error getting upcoming reminders:', error);
    return [];
  }
}

async function completeReminder(id) {
  try {
    const reminder = await prisma.reminder.update({
      where: { id },
      data: { completed: true }
    });
    return reminder;
  } catch (error) {
    logger.error('Error completing reminder:', error);
    throw error;
  }
}

// === MESSAGE TRACKING ===
async function markMessageProcessed(messageId, processingType, storedIn = null) {
  try {
    const processed = await prisma.processedMessage.upsert({
      where: { messageId },
      update: { processingType, storedIn },
      create: { messageId, processingType, storedIn }
    });
    return processed;
  } catch (error) {
    logger.error('Error marking message processed:', error);
    throw error;
  }
}

async function isMessageProcessed(messageId) {
  try {
    const message = await prisma.processedMessage.findUnique({
      where: { messageId }
    });
    return message !== null;
  } catch (error) {
    logger.error('Error checking if message processed:', error);
    return false;
  }
}

async function getUnprocessedCount() {
  try {
    const count = await prisma.processedMessage.count();
    return count;
  } catch (error) {
    logger.error('Error getting unprocessed count:', error);
    return 0;
  }
}

// Cleanup on shutdown
process.on('beforeExit', async () => {
  await prisma.$disconnect();
});

module.exports = {
  prisma,
  initializeSQL,
  addEvent,
  getRecentEvents,
  searchEvents,
  addTodo,
  getTodos,
  completeTodo,
  deleteTodo,
  addReminder,
  getUpcomingReminders,
  completeReminder,
  markMessageProcessed,
  isMessageProcessed,
  getUnprocessedCount
};
```

---

## Phase 3: Vector Database Module

### Create: `src/modules/vectorDB.js`

```javascript
const { ChromaClient } = require('chromadb');
const OpenAI = require('openai');
const config = require('../config/config');
const logger = require('../utils/logger');
const { v4: uuidv4 } = require('uuid');

let chromaClient = null;
let collection = null;
let openai = null;

/**
 * Initialize Vector DB
 */
async function initializeVectorDB() {
  if (collection) {
    return collection;
  }

  try {
    // Initialize OpenAI for embeddings
    if (!openai) {
      openai = new OpenAI({
        apiKey: config.openai.apiKey,
      });
    }

    // Initialize Chroma
    chromaClient = new ChromaClient({
      path: config.vectorDB.path,
    });

    // Test connection
    const heartbeat = await chromaClient.heartbeat();
    logger.success('ChromaDB connection successful');

    // Get or create collection
    collection = await chromaClient.getOrCreateCollection({
      name: config.vectorDB.collectionName,
      embeddingFunction: null, // We provide embeddings via OpenAI
    });

    logger.success(`Vector DB collection initialized: ${config.vectorDB.collectionName}`);
    return collection;
  } catch (error) {
    logger.error('Failed to initialize Vector DB:', error.message);
    logger.warn('Make sure ChromaDB is running: docker run -d -p 8000:8000 chromadb/chroma');
    return null;
  }
}

/**
 * Generate embedding for text using OpenAI
 */
async function generateEmbedding(text) {
  try {
    const response = await openai.embeddings.create({
      model: 'text-embedding-3-small',
      input: text,
    });
    return response.data[0].embedding;
  } catch (error) {
    logger.error('Error generating embedding:', error.message);
    throw error;
  }
}

/**
 * Search for relevant memories
 */
async function searchMemories(query, limit = 3) {
  try {
    if (!collection) {
      await initializeVectorDB();
    }
    if (!collection) {
      return [];
    }

    const queryEmbedding = await generateEmbedding(query);
    
    const results = await collection.query({
      queryEmbeddings: [queryEmbedding],
      nResults: limit,
    });

    if (!results.documents[0] || results.documents[0].length === 0) {
      return [];
    }

    return results.documents[0].map((doc, idx) => ({
      narrative: doc,
      metadata: results.metadatas[0][idx],
      distance: results.distances[0][idx]
    }));
  } catch (error) {
    logger.error('Error searching memories:', error);
    return [];
  }
}

/**
 * Check for duplicate facts using semantic similarity
 */
async function checkDuplicate(factText, threshold = 0.15) {
  try {
    if (!collection) {
      await initializeVectorDB();
    }
    if (!collection) {
      return { isDuplicate: false };
    }

    const embedding = await generateEmbedding(factText);
    
    const results = await collection.query({
      queryEmbeddings: [embedding],
      nResults: 1
    });

    if (results.distances[0] && results.distances[0][0] < threshold) {
      return {
        isDuplicate: true,
        existingId: results.ids[0][0],
        existingText: results.documents[0][0],
        similarity: results.distances[0][0]
      };
    }

    return { isDuplicate: false };
  } catch (error) {
    logger.error('Error checking duplicate:', error);
    return { isDuplicate: false };
  }
}

/**
 * Enrich existing fact with new information
 */
async function enrichExistingFact(factId, newText, newMessageId, newTimestamp) {
  try {
    if (!collection) return;

    // Get existing metadata
    const existing = await collection.get({ ids: [factId] });
    const existingMetadata = existing.metadatas[0] || {};
    
    const sourceMessages = existingMetadata.source_messages 
      ? existingMetadata.source_messages + ',' + newMessageId
      : newMessageId;

    await collection.update({
      ids: [factId],
      metadatas: [{
        ...existingMetadata,
        last_updated: newTimestamp,
        source_messages: sourceMessages,
        enriched: true
      }]
    });

    logger.info(`Enriched existing fact: ${factId}`);
  } catch (error) {
    logger.error('Error enriching fact:', error);
  }
}

/**
 * Store fact safely with deduplication
 */
async function storeFactSafely(factText, messageId, timestamp, category = 'fact') {
  try {
    if (!collection) {
      await initializeVectorDB();
    }
    if (!collection) {
      return { stored: 'failed', reason: 'no collection' };
    }

    // Check for duplicates
    const duplicate = await checkDuplicate(factText, config.memory.dedupThreshold);
    
    if (duplicate.isDuplicate) {
      await enrichExistingFact(duplicate.existingId, factText, messageId, timestamp.toISOString());
      return { stored: 'enriched', id: duplicate.existingId };
    }

    // Store new fact
    const embedding = await generateEmbedding(factText);
    const id = uuidv4();

    await collection.add({
      ids: [id],
      documents: [factText],
      embeddings: [embedding],
      metadatas: [{
        source_message_id: messageId,
        timestamp: timestamp.toISOString(),
        category: category,
        processed_type: 'immediate',
        source_messages: messageId
      }]
    });

    logger.info(`Stored new fact: ${factText.substring(0, 50)}...`);
    return { stored: 'new', id };
  } catch (error) {
    logger.error('Error storing fact:', error);
    return { stored: 'failed', reason: error.message };
  }
}

/**
 * Store memory chunk (batch processing)
 */
async function storeMemory(narrative, metadata = {}) {
  try {
    if (!collection) {
      await initializeVectorDB();
    }
    if (!collection) {
      return;
    }

    const embedding = await generateEmbedding(narrative);
    const id = uuidv4();

    await collection.add({
      ids: [id],
      documents: [narrative],
      embeddings: [embedding],
      metadatas: [{
        ...metadata,
        timestamp: new Date().toISOString(),
        processed_type: 'batch'
      }]
    });

    logger.debug(`Stored memory chunk: ${narrative.substring(0, 50)}...`);
  } catch (error) {
    logger.error('Error storing memory:', error);
  }
}

module.exports = {
  initializeVectorDB,
  generateEmbedding,
  searchMemories,
  checkDuplicate,
  enrichExistingFact,
  storeFactSafely,
  storeMemory
};
```

---

## Phase 4: Memory Processor Module

### Create: `src/modules/memoryProcessor.js`

```javascript
const OpenAI = require('openai');
const config = require('../config/config');
const logger = require('../utils/logger');

let openai = null;

/**
 * Initialize OpenAI
 */
function initializeOpenAI() {
  if (!openai) {
    openai = new OpenAI({
      apiKey: config.openai.apiKey,
    });
  }
  return openai;
}

/**
 * Detect if message contains important information
 */
async function detectImportance(message, conversationContext) {
  try {
    const ai = initializeOpenAI();
    const contextWindow = conversationContext.slice(-config.memory.contextWindowSize);

    const response = await ai.chat.completions.create({
      model: 'gpt-4o',
      messages: [{
        role: 'system',
        content: `Determine if this message contains important information worth storing immediately.

Important information includes:
- Tasks, todos, reminders
- Deadlines, appointments, scheduled events
- Important facts about the user (birthday, preferences, relationships)
- Critical decisions or commitments
- Information user explicitly asks to remember

NOT important:
- Casual chat, greetings
- Jokes, memes, sarcasm
- Hypothetical discussions
- General knowledge questions

Respond with JSON: {"important": boolean, "reason": string, "category": "fact|event|todo|reminder|none"}`
      }, {
        role: 'user',
        content: `Context:\n${contextWindow.map(m => m.content).join('\n')}\n\nCurrent message:\n${message}`
      }],
      temperature: 0.2,
      response_format: { type: "json_object" }
    });

    return JSON.parse(response.choices[0].message.content);
  } catch (error) {
    logger.error('Error detecting importance:', error);
    return { important: false, reason: 'error', category: 'none' };
  }
}

/**
 * Extract facts with conversation context
 */
async function extractWithContext(currentMessage, conversationCache, messageId) {
  try {
    const ai = initializeOpenAI();
    const contextWindow = conversationCache.slice(-config.memory.contextWindowSize);

    const response = await ai.chat.completions.create({
      model: 'gpt-4o',
      messages: [{
        role: 'system',
        content: `Extract important facts from this conversation snippet.

CRITICAL RULES:
1. ONLY extract information EXPLICITLY stated
2. Do NOT infer, assume, or create plausible facts
3. Do NOT extract jokes, sarcasm, or hypotheticals
4. Consider conversation context
5. If uncertain, DO NOT include it

Categorize each fact as:
- "fact" (time-irrelevant): preferences, attributes, relationships
- "event" (time-relevant): things that happened on specific dates
- "todo" (actionable): tasks to complete
- "reminder" (scheduled): future notifications

Return JSON: {"facts": [{"text": string, "category": string, "confidence": number}]}`
      }, {
        role: 'user',
        content: `Context:\n${contextWindow.map(m => m.content).join('\n')}\n\nCurrent message:\n${currentMessage}`
      }],
      temperature: 0.1,
      response_format: { type: "json_object" }
    });

    const result = JSON.parse(response.choices[0].message.content);
    return result.facts || [];
  } catch (error) {
    logger.error('Error extracting facts:', error);
    return [];
  }
}

/**
 * Process conversations for batch storage
 */
async function processConversations(messages) {
  try {
    const ai = initializeOpenAI();

    if (!messages || messages.length === 0) {
      return [];
    }

    const conversationText = messages.map(m => m.content).join('\n');

    const response = await ai.chat.completions.create({
      model: 'gpt-4o',
      messages: [{
        role: 'system',
        content: `Extract important facts from these conversations.

STRICT RULES:
1. ONLY extract EXPLICITLY stated information
2. Do NOT infer or assume
3. Do NOT extract jokes or sarcasm
4. Each chunk must be self-contained and factual
5. Separate unrelated topics with |

Output only memory chunks separated by |.`
      }, {
        role: 'user',
        content: conversationText
      }],
      temperature: 0.1,
      max_tokens: 2000
    });

    const narrativeText = response.choices[0].message.content.trim();
    
    const chunks = narrativeText
      .split('|')
      .map(chunk => chunk.trim())
      .filter(chunk => chunk.length > 20)
      .map(chunk => ({
        narrative: chunk,
        metadata: {
          message_count: messages.length,
          created_at: new Date().toISOString()
        }
      }));

    return chunks;
  } catch (error) {
    logger.error('Error processing conversations:', error);
    return [];
  }
}

/**
 * Categorize into time-relevant vs time-irrelevant
 */
async function categorizeMemories(conversationText) {
  try {
    const ai = initializeOpenAI();

    const response = await ai.chat.completions.create({
      model: 'gpt-4o',
      messages: [{
        role: 'system',
        content: `Separate information into time-relevant and time-irrelevant categories.

Time-RELEVANT (SQL):
- Events on specific dates
- Scheduled future events, deadlines
- Time-based patterns

Time-IRRELEVANT (Vector DB):
- User preferences, likes/dislikes
- Personality traits
- Relationships, skills, interests

Return JSON: {
  "time_relevant": [{"text": string, "date": string, "type": "event|todo|pattern"}],
  "time_irrelevant": [{"text": string}]
}`
      }, {
        role: 'user',
        content: conversationText
      }],
      temperature: 0.1,
      response_format: { type: "json_object" }
    });

    return JSON.parse(response.choices[0].message.content);
  } catch (error) {
    logger.error('Error categorizing memories:', error);
    return { time_relevant: [], time_irrelevant: [] };
  }
}

/**
 * Reformulate query for better search
 */
async function reformulateQuery(query, conversationContext) {
  try {
    const ai = initializeOpenAI();
    const recentContext = conversationContext.slice(-3);

    if (recentContext.length === 0) {
      return query;
    }

    const response = await ai.chat.completions.create({
      model: 'gpt-4o',
      messages: [{
        role: 'system',
        content: 'Reformulate the query to better search for relevant memories. Keep it concise. Return only the reformulated query, nothing else.'
      }, {
        role: 'user',
        content: `Context:\n${recentContext.map(m => m.content).join('\n')}\n\nQuery: ${query}`
      }],
      temperature: 0.3,
      max_tokens: 100
    });

    return response.choices[0].message.content.trim();
  } catch (error) {
    logger.warn('Error reformulating query:', error);
    return query;
  }
}

module.exports = {
  initializeOpenAI,
  detectImportance,
  extractWithContext,
  processConversations,
  categorizeMemories,
  reformulateQuery
};
```

---

## Phase 5: AI Chat Handler with Function Calling

### Create: `src/modules/aiChat.js`

```javascript
const OpenAI = require('openai');
const config = require('../config/config');
const logger = require('../utils/logger');
const { searchMemories } = require('./vectorDB');
const { storeFactSafely } = require('./vectorDB');
const { detectImportance, extractWithContext, reformulateQuery } = require('./memoryProcessor');
const { addEvent, addTodo, getTodos, completeTodo, deleteTodo, getRecentEvents, markMessageProcessed } = require('./sqlDB');

let openai = null;
let conversation_cache = [];

/**
 * Initialize OpenAI
 */
function initializeOpenAI() {
  if (!config.openai.apiKey) {
    logger.warn('OpenAI API key not configured');
    return null;
  }

  if (!openai) {
    openai = new OpenAI({
      apiKey: config.openai.apiKey,
    });
    logger.success('OpenAI initialized successfully');
  }

  return openai;
}

/**
 * Define tools/functions for the AI to use
 */
const tools = [
  {
    type: 'function',
    function: {
      name: 'add_todo',
      description: 'Add a new task to the todo list',
      parameters: {
        type: 'object',
        properties: {
          task: {
            type: 'string',
            description: 'The task description'
          },
          priority: {
            type: 'string',
            enum: ['low', 'normal', 'high'],
            description: 'Task priority level'
          }
        },
        required: ['task']
      }
    }
  },
  {
    type: 'function',
    function: {
      name: 'get_todos',
      description: 'Get all pending todos from the todo list',
      parameters: {
        type: 'object',
        properties: {
          include_completed: {
            type: 'boolean',
            description: 'Whether to include completed todos'
          }
        }
      }
    }
  },
  {
    type: 'function',
    function: {
      name: 'complete_todo',
      description: 'Mark a todo as completed',
      parameters: {
        type: 'object',
        properties: {
          task_description: {
            type: 'string',
            description: 'Description or partial match of the task to complete'
          }
        },
        required: ['task_description']
      }
    }
  },
  {
    type: 'function',
    function: {
      name: 'delete_todo',
      description: 'Delete a todo from the list',
      parameters: {
        type: 'object',
        properties: {
          task_description: {
            type: 'string',
            description: 'Description or partial match of the task to delete'
          }
        },
        required: ['task_description']
      }
    }
  }
];

/**
 * Execute tool calls
 */
async function executeToolCall(toolCall) {
  const functionName = toolCall.function.name;
  const args = JSON.parse(toolCall.function.arguments);

  logger.info(`Executing tool: ${functionName}`, args);

  try {
    switch (functionName) {
      case 'add_todo':
        const newTodo = await addTodo(args.task, null, args.priority || 'normal');
        return { success: true, message: `Added todo: ${args.task}`, todo: newTodo };

      case 'get_todos':
        const todos = await getTodos(args.include_completed || false);
        return { 
          success: true, 
          todos: todos.map((t, i) => ({
            number: i + 1,
            task: t.task,
            priority: t.priority,
            completed: t.completed,
            dueDate: t.dueDate
          }))
        };

      case 'complete_todo':
        const allTodos = await getTodos(false);
        const todoToComplete = allTodos.find(t => 
          t.task.toLowerCase().includes(args.task_description.toLowerCase())
        );
        
        if (!todoToComplete) {
          return { success: false, message: `No todo found matching: ${args.task_description}` };
        }
        
        await completeTodo(todoToComplete.id);
        return { success: true, message: `Completed: ${todoToComplete.task}` };

      case 'delete_todo':
        const todosToSearch = await getTodos(false);
        const todoToDelete = todosToSearch.find(t => 
          t.task.toLowerCase().includes(args.task_description.toLowerCase())
        );
        
        if (!todoToDelete) {
          return { success: false, message: `No todo found matching: ${args.task_description}` };
        }
        
        await deleteTodo(todoToDelete.id);
        return { success: true, message: `Deleted: ${todoToDelete.task}` };

      default:
        return { success: false, message: `Unknown function: ${functionName}` };
    }
  } catch (error) {
    logger.error(`Error executing ${functionName}:`, error);
    return { success: false, message: `Error: ${error.message}` };
  }
}

/**
 * Handle AI chat interaction
 */
async function handleAIChat(message, client) {
  const ai = initializeOpenAI();
  
  if (!ai) {
    return message.channel.send('AI chat is not configured. Please set up your OpenAI API key.');
  }

  try {
    // Remove mention from message
    let input = message.content.replace(/<@!?\d+>/g, '').trim();
    
    if (!input || input === "") {
      return message.channel.send('What can I help you with?');
    }

    // Add to conversation cache
    const userMessage = {
      role: 'user',
      content: `${message.author.username}: ${input}`,
      messageId: message.id,
      timestamp: new Date()
    };
    conversation_cache.push(userMessage);

    // Show typing
    message.channel.startTyping();

    // === IMMEDIATE STORAGE ===
    // Note: Todos are handled by AI function calling, not immediate storage
    const importance = await detectImportance(input, conversation_cache);
    
    if (importance.important && importance.category !== 'todo') {
      logger.info(`[Important] ${importance.reason}`);
      
      // Extract facts with context
      const facts = await extractWithContext(input, conversation_cache, message.id);
      
      // Store each fact (exclude todos - those are managed by AI tools)
      for (const fact of facts) {
        if (fact.category === 'fact') {
          await storeFactSafely(fact.text, message.id, new Date(), fact.category);
        } else if (fact.category === 'event') {
          await addEvent(new Date().toISOString(), fact.text, message.author.username, input);
        }
        // Todos are skipped here - AI function calling handles them better
      }
      
      // Mark as processed
      await markMessageProcessed(message.id, 'immediate', importance.category);
    }

    // === CONTEXT RETRIEVAL ===
    // Reformulate query
    const searchQuery = await reformulateQuery(input, conversation_cache);
    
    // Search vector DB
    const relevantMemories = await searchMemories(searchQuery, 3);
    
    // Get recent events (but don't get todos here - let AI fetch via tools)
    const recentEvents = await getRecentEvents(7);

    // === BUILD CONTEXT ===
    const messages = [
      {
        role: 'system',
        content: `You are a helpful and friendly AI assistant with access to todo management tools.

Your purpose:
1. Be genuinely helpful and supportive
2. Help manage todos, reminders, and events using available tools
3. Remember conversations and information accurately
4. Provide concise but thorough responses (this is Discord)

When the user mentions tasks, todos, or things to remember:
- Use add_todo to create tasks
- Use get_todos to check current tasks
- Use complete_todo to mark tasks as done
- Use delete_todo to remove tasks

Personality:
- Friendly and warm, occasionally playful
- Proactive in offering help
- Admits when you don't know something
- References past conversations naturally

Respond naturally and helpfully.`
      }
    ];

    // Add relevant memories
    if (relevantMemories.length > 0) {
      const memoryContext = relevantMemories.map(m => m.narrative).join(' | ');
      messages.push({
        role: 'system',
        content: `Relevant memories: ${memoryContext}`
      });
    }

    // Add recent events
    if (recentEvents.length > 0) {
      const eventsContext = recentEvents
        .map(e => `${e.date}: ${e.description}`)
        .join('; ');
      messages.push({
        role: 'system',
        content: `Recent events (last 7 days): ${eventsContext}`
      });
    }

    // Add conversation history
    const recentConvo = conversation_cache.slice(-10);
    messages.push(...recentConvo);

    // === GENERATE RESPONSE WITH TOOL SUPPORT ===
    let response = await ai.chat.completions.create({
      model: 'gpt-4o',
      messages: messages,
      tools: tools,
      tool_choice: 'auto',
      temperature: 0.7,
      max_tokens: 500
    });

    let responseMessage = response.choices[0].message;

    // Handle tool calls
    while (responseMessage.tool_calls && responseMessage.tool_calls.length > 0) {
      // Add assistant's response with tool calls to messages
      messages.push(responseMessage);

      // Execute each tool call
      for (const toolCall of responseMessage.tool_calls) {
        const toolResult = await executeToolCall(toolCall);
        
        // Add tool response to messages
        messages.push({
          role: 'tool',
          tool_call_id: toolCall.id,
          content: JSON.stringify(toolResult)
        });

        logger.info(`Tool result: ${JSON.stringify(toolResult)}`);
      }

      // Get next response from AI with tool results
      response = await ai.chat.completions.create({
        model: 'gpt-4o',
        messages: messages,
        tools: tools,
        tool_choice: 'auto',
        temperature: 0.7,
        max_tokens: 500
      });

      responseMessage = response.choices[0].message;
    }

    const botReply = responseMessage.content;

    // Add bot response to cache
    conversation_cache.push({
      role: 'assistant',
      content: botReply
    });

    // Trim cache if too long
    if (conversation_cache.length > 50) {
      conversation_cache = conversation_cache.slice(-40);
    }

    message.channel.stopTyping();
    return message.channel.send(botReply);

  } catch (error) {
    message.channel.stopTyping();
    logger.error('Error in AI chat:', error);
    return message.channel.send('Sorry, I encountered an error. Please try again.');
  }
}

/**
 * Get conversation cache (for scheduler)
 */
function getConversationCache() {
  return conversation_cache;
}

/**
 * Clear conversation cache
 */
function clearConversationCache() {
  conversation_cache = [];
}

module.exports = {
  handleAIChat,
  getConversationCache,
  clearConversationCache
};
```

---

## Phase 6: Scheduler (Batch Processing)

### Create: `src/utils/scheduler.js`

```javascript
const cron = require('node-cron');
const logger = require('./logger');
const { getConversationCache, clearConversationCache } = require('../modules/aiChat');
const { processConversations, categorizeMemories } = require('../modules/memoryProcessor');
const { storeMemory } = require('../modules/vectorDB');
const { addEvent, isMessageProcessed, markMessageProcessed } = require('../modules/sqlDB');

// Run daily at 11 PM
cron.schedule('0 23 * * *', async () => {
  logger.info('=== Starting daily memory consolidation ===');

  try {
    const conversationCache = getConversationCache();

    // Filter unprocessed messages
    const unprocessedMessages = [];
    for (const msg of conversationCache) {
      if (msg.messageId && !(await isMessageProcessed(msg.messageId))) {
        unprocessedMessages.push(msg);
      }
    }

    if (unprocessedMessages.length === 0) {
      logger.info('No unprocessed messages to consolidate');
      return;
    }

    logger.info(`Processing ${unprocessedMessages.length} unprocessed messages...`);

    // Process conversations
    const chunks = await processConversations(unprocessedMessages);

    if (chunks.length > 0) {
      logger.info(`Extracted ${chunks.length} memory chunks`);

      // Store each chunk
      for (const chunk of chunks) {
        await storeMemory(chunk.narrative, chunk.metadata);
      }

      // Mark messages as processed
      for (const msg of unprocessedMessages) {
        if (msg.messageId) {
          await markMessageProcessed(msg.messageId, 'batch', 'consolidated');
        }
      }

      logger.success(`Stored ${chunks.length} memory chunks`);
    }

    // Clear conversation cache
    clearConversationCache();
    logger.success('=== Daily memory consolidation complete ===');

  } catch (error) {
    logger.error('Error in daily consolidation:', error);
  }
});

logger.info('Scheduler initialized - Daily consolidation at 11 PM');
```

---

## Phase 7: Commands

### Create: `src/commands/todo.js`

```javascript
const { getTodos, addTodo, completeTodo, deleteTodo } = require('../modules/sqlDB');

module.exports = {
  name: 'todo',
  aliases: ['task', 't'],
  description: 'Manage your todo list',
  usage: '!todo [add|list|done|delete] [task]',
  execute: async (message, args) => {
    const subcommand = args[0]?.toLowerCase();

    try {
      switch (subcommand) {
        case 'add':
          const task = args.slice(1).join(' ');
          if (!task) return message.reply('Please specify a task!');
          await addTodo(task, null, 'normal');
          return message.reply(`‚úÖ Added: ${task}`);

        case 'list':
        case 'show':
          const todos = await getTodos(false);
          if (todos.length === 0) {
            return message.reply('No pending todos! üéâ');
          }
          const list = todos.map((t, i) => 
            `${i + 1}. ${t.task}${t.dueDate ? ` (due: ${t.dueDate})` : ''}`
          ).join('\n');
          return message.reply(`üìù **Your todos:**\n${list}`);

        case 'done':
        case 'complete':
          const todoIndex = parseInt(args[1]);
          if (!todoIndex || todoIndex < 1) {
            return message.reply('Please specify a valid todo number!');
          }
          const allTodos = await getTodos(false);
          if (todoIndex > allTodos.length) {
            return message.reply(`Todo #${todoIndex} doesn't exist!`);
          }
          const todoToComplete = allTodos[todoIndex - 1];
          await completeTodo(todoToComplete.id);
          return message.reply(`‚úÖ Completed: ${todoToComplete.task}`);

        case 'delete':
        case 'remove':
          const deleteIndex = parseInt(args[1]);
          if (!deleteIndex || deleteIndex < 1) {
            return message.reply('Please specify a valid todo number!');
          }
          const todosToDelete = await getTodos(false);
          if (deleteIndex > todosToDelete.length) {
            return message.reply(`Todo #${deleteIndex} doesn't exist!`);
          }
          const todoToDelete = todosToDelete[deleteIndex - 1];
          await deleteTodo(todoToDelete.id);
          return message.reply(`üóëÔ∏è Deleted: ${todoToDelete.task}`);

        default:
          return message.reply('Usage: `!todo [add|list|done|delete] [task]`\n\nExamples:\n`!todo add Buy groceries`\n`!todo list`\n`!todo done 1`\n`!todo delete 2`');
      }
    } catch (error) {
      console.error('Error in todo command:', error);
      return message.reply('An error occurred while managing your todos.');
    }
  }
};
```

### Create: `src/commands/help.js`

```javascript
const config = require('../config/config');

module.exports = {
  name: 'help',
  description: 'List all commands',
  aliases: ['commands', 'h'],
  usage: '!help [command]',
  execute: (message, args, client) => {
    const { prefix } = config.discord;
    const { commands } = client;

    if (!args.length) {
      const commandList = commands.map(cmd => `\`${prefix}${cmd.name}\``).join(', ');
      
      return message.channel.send(
        `**Available Commands:**\n${commandList}\n\nUse \`${prefix}help [command]\` for details.` +
        `\n\n**AI Chat:** Just mention me (@${client.user.username}) to chat!`
      );
    }

    const name = args[0].toLowerCase();
    const command = commands.get(name) || commands.find(c => c.aliases && c.aliases.includes(name));

    if (!command) {
      return message.reply('That command doesn\'t exist!');
    }

    let reply = `**Command:** ${command.name}\n`;
    if (command.aliases) reply += `**Aliases:** ${command.aliases.join(', ')}\n`;
    if (command.description) reply += `**Description:** ${command.description}\n`;
    if (command.usage) reply += `**Usage:** ${command.usage}`;

    message.channel.send(reply);
  },
};
```

### Create: `src/commands/ping.js`

```javascript
module.exports = {
  name: 'ping',
  description: 'Check bot latency',
  execute: (message) => {
    const latency = Date.now() - message.createdTimestamp;
    message.reply(`üèì Pong! Latency: ${latency}ms`);
  },
};
```

---

## COMPLETE! üéâ

You now have a complete Discord bot with:

‚úÖ **Accurate Memory System**
- No hallucinations (temp 0.1, strict prompts)
- Semantic deduplication
- Source message tracking

‚úÖ **Dual Database**
- ChromaDB for time-irrelevant facts
- Prisma + SQLite for events, todos, reminders

‚úÖ **Smart Storage**
- Immediate storage for important info
- Batch processing at 11 PM
- Context-aware extraction

‚úÖ **Natural Language Todo Management** üÜï
- AI chatbot with function calling tools
- Say "remind me to buy milk" ‚Üí Auto-creates todo
- Ask "what are my tasks?" ‚Üí AI fetches & lists them
- Say "I finished buying groceries" ‚Üí Marks as complete
- No commands needed - just chat naturally!

‚úÖ **Commands (for manual control)**
- `!todo` - Manage todos via commands
- `!help` - List commands
- `!ping` - Check latency
- @mention for AI chat with tool access

## Example Conversations

**Natural Todo Management:**
```
User: "@bot remind me to call mom tomorrow"
Bot: "‚úÖ I've added 'call mom tomorrow' to your todo list!"

User: "@bot what do I need to do?"
Bot: "Here are your pending tasks:
1. Call mom tomorrow
2. Buy groceries
3. Finish project report"

User: "@bot I called mom"
Bot: "Great! I've marked 'call mom tomorrow' as complete. ‚úÖ"

User: "@bot actually, remove the groceries task"
Bot: "Done! I've removed 'Buy groceries' from your list. üóëÔ∏è"
```

**Command-Based (Alternative):**
```
!todo add Buy milk
!todo list
!todo done 1
!todo delete 2
```

## Quick Start

```bash
# 1. Setup project
mkdir assistant-bot && cd assistant-bot
npm init -y

# 2. Install dependencies
npm install discord.js@12.5.3 openai@4.0.0 chromadb@1.5.0 @prisma/client dotenv node-cron uuid chalk@4.1.2
npm install -D nodemon prisma

# 3. Initialize Prisma
npx prisma init --datasource-provider sqlite

# 4. Create all files from this guide (including prisma/schema.prisma)

# 5. Configure .env with your tokens and DATABASE_URL

# 6. Run Prisma migration
npx prisma migrate dev --name init

# 7. Start ChromaDB
docker run -d -p 8000:8000 chromadb/chroma

# 8. Run the bot
npm start

# Optional: View database with Prisma Studio
npm run db:studio
```

## Testing Checklist

**Basic Functionality:**
- [ ] Bot connects to Discord
- [ ] Prisma database migrated successfully
- [ ] Responds to mentions with AI

**Command-Based Todos:**
- [ ] `!todo add Buy milk` creates a task
- [ ] `!todo list` shows all tasks
- [ ] `!todo done 1` completes a task
- [ ] `!todo delete 1` removes a task

**Natural Language Todos (Function Calling):**
- [ ] "@bot remind me to buy groceries" creates a todo
- [ ] "@bot what are my tasks?" lists todos using AI tool
- [ ] "@bot I finished the groceries" marks todo as complete
- [ ] "@bot remove the milk task" deletes a todo

**Memory System:**
- [ ] Important info gets stored immediately
- [ ] No duplicate facts stored
- [ ] Batch processing runs at 11 PM
- [ ] Memory retrieval works in AI responses

## Future Enhancements

- Multi-user support (add userId field to Prisma models)
- Proactive reminders (cron job checking every 5 min)
- Calendar integration (Google Calendar API)
- Advanced natural language date parsing ("remind me tomorrow at 3pm")
- Voice command support
- Prisma Studio for database management UI
- Due date extraction from natural language
- Priority detection from conversation tone

---

## Prisma Tips

**View your database:**
```bash
npx prisma studio
# Opens at http://localhost:5555
```

**Update schema:**
1. Edit `prisma/schema.prisma`
2. Run `npx prisma migrate dev --name your_change_name`
3. Restart bot

**Reset database:**
```bash
npx prisma migrate reset
# WARNING: Deletes all data!
```

**Generate Prisma Client after pulling:**
```bash
npx prisma generate
```

---

## Architecture Notes

### Why Function Calling for Todos?

**Todos are managed via OpenAI Function Calling instead of immediate storage because:**

1. **Better Intent Detection** - AI understands nuanced requests:
   - "remind me to..." ‚Üí add_todo
   - "I need to..." ‚Üí add_todo
   - "I finished..." ‚Üí complete_todo
   - "forget about..." ‚Üí delete_todo

2. **Natural Conversation Flow** - AI can:
   - Confirm what was added
   - Ask clarifying questions
   - Handle ambiguous task descriptions
   - Provide helpful context

3. **No Duplicates** - Function calling happens during response generation, not before
   - Immediate storage is skipped for todos (see `aiChat.js` line with `importance.category !== 'todo'`)

4. **Rich Responses** - AI formats results naturally:
   - "‚úÖ I've added that to your todo list!"
   - "You have 3 pending tasks: ..."
   - vs raw "Added todo #5"

**Immediate storage is still used for:**
- Facts: "I like pizza" ‚Üí stored in vector DB
- Events: "I met John yesterday" ‚Üí stored in SQL events table

---

**Your bot is ready to be useful! üöÄ**
